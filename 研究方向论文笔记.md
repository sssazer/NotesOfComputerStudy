Effective Regression Test Case Selection: A Systematic Literature Review 2017

用于Regression Test Selection的研究方法

- Mining and Learning
- Model Based Testing
- Program Slicing
- Control Flow Graph（CFG）
- Firewall
- Other techniques



# 1. 找方向

找有开源数据集，**近两年**做的人多的（而且是发水刊多的，保证能发出去水刊）

change analysis （可能和项目相关，但是做的人比较少）

Vulnerability analysis：代码缺陷检测

code learning：代码学习，这应该是个大方向，可以用里面的模型应用到具体领域

# 2. 找基准模型

## 2.0 需要做的事

1. 找目标论文

找**近两年**有开源代码的论文，一般在顶刊顶会才会开源，如果代码开源一般会放在摘要最后一行，是一个github链接

看论文就看introduction的方法摘要部分和方法部分，找到它的基准模型和模块，比如是A+b+c。

怎么找A？：看消融实验，肯定最后加完模块的模型要和不加模块的模型进行对比，要比单纯的使用A好，才能水论文

之后就可以拿A、A+b、A+c、A+b+c、A+b+c-d（减去某一行代码，或某一个更小的模块）等等来做基准模型

2. 复现开源代码

   复现不了就换一个

# 3. 找模块

近5~10年

## 3.1 找目标论文

# 4 缝模块



# NLP和深度学习名词

## Pre-trained Model 和 fine-tune

预训练模型 和 微调

预训练模型就是别人使用大量数据训练好的模型，训练出来一套参数。

微调就是在别人的预训练模型的基础上，也就是将别人的参数作为初始参数，再使用自己的特定任务的数据进行训练，以拿来解决自己的问题（被称为下游任务）。

[深度学习笔记（一）：模型微调fine-tune](https://blog.csdn.net/sinat_36831051/article/details/84988174)

### fine-tune微调

1. 得到一个预训练模型

2. 创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。

   假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集；

   还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。

3. 为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。

   ![fine-tune](D:\CS_Source\myNote-of-ComputerStudy\机器学习\3\fine-tune.png)

4. 在目标数据集（例如椅子数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。 
